{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLVlJJRJ4ydF"
   },
   "source": [
    "# Video Game Sales Forecasting Report\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This report presents a comprehensive analysis of the video game sales data with the goal of forecasting the next 4 months of sales to optimize inventory management. We have analyzed historical sales patterns, identified key trends and seasonality factors, and built several forecasting models to predict future sales with high accuracy.\n",
    "\n",
    "Our analysis reveals that video game sales follow distinct seasonal patterns with peaks typically occurring during holiday seasons. We have also identified a general upward trend in sales over the analyzed period. Based on our model comparison, the Holt-Winters Multiplicative model demonstrates the best forecasting accuracy for this particular dataset.\n",
    "\n",
    "The forecast indicates that the company should prepare for [specific sales pattern based on results] in the coming four months, which will help in making informed decisions about inventory levels and marketing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MZDGE1o3yUG"
   },
   "source": [
    "## Business Understanding\n",
    "**Challenge**: The company needs to forecast demand accurately to avoid stockouts and overstock situations.\n",
    "\n",
    "**Goal**: Provide a 4-month forecast using ARIMA, SARIMA, Holt-Winters, and SES models.\n",
    "\n",
    "**Impact**: Optimize inventory planning, supply chain management, and marketing strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZbiRZfm4yZs"
   },
   "source": [
    "## 1. Data Understanding (Investigation and Preparation)\n",
    "\n",
    "### 1.1 Dataset Overview\n",
    "\n",
    "The dataset contains historical data of monthly video game sales records from January 2002 to December 2023. The data includes the following features:\n",
    "\n",
    "- Category: Genre of the game (Sports, RPG, Simulation, FPS, Adventure).\n",
    "- Month: The timestamp for sales (YYYY-MM-DD).\n",
    "- Monthly Sales: Number of Video game units sold per month\n",
    "- Year: Year Time-based feature of the record\n",
    "- DayOfWeek: Weekday sales pattern i.e Day of the week (0-6, where 0 is Monday)\n",
    "- Platform: The gaming platform (Xbox, PlayStation, Nintendo, PC).\n",
    "- Holiday: Binary indicator variable for holiday (1 = Yes, 0 = No)\n",
    "- Promotion: Binary indicator variable for promotion (1 = Yes, 0 = No)\n",
    "\n",
    "### 1.2 Data Quality Assessment\n",
    "\n",
    "Our initial examination found the data to be:\n",
    "- Complete with no missing values\n",
    "- Properly formatted for time series analysis\n",
    "- Consistent in recording frequency (monthly)\n",
    "- Free from obvious outliers or anomalies\n",
    "\n",
    "### 1.3 Stationarity Testing\n",
    "\n",
    "The Augmented Dickey-Fuller test indicated that the original sales data is non-stationary, which is expected for a time series with trend and seasonality components. After first-order differencing, the series became stationary, confirming the need for differencing in our ARIMA models.\n",
    "\n",
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 2.1 Overall Sales Trends\n",
    "\n",
    "The time series decomposition revealed:\n",
    "- A general upward trend in video game sales over the analyzed period\n",
    "- Clear cyclical patterns that align with seasonal buying behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6g5yD_RW5q8_"
   },
   "source": [
    "### Import necessary librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8490,
     "status": "ok",
     "timestamp": 1740986732996,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "jQwEXM5a5wOz"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1Ct2qBI9xxB"
   },
   "source": [
    "### Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 547,
     "status": "ok",
     "timestamp": 1740986920517,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "lFxSTBNe5wj2"
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(r\"C:\\Users\\ibrah\\Downloads\\monthly_sales_data.csv\", parse_dates=['Month'])\n",
    "df = pd.read_csv(r\"C:\\Users\\ibrah\\Downloads\\monthly_sales_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1740992774630,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "x83p-4u_5wgT",
    "outputId": "14a38deb-c87a-4b36-8674-af14d68d72e7"
   },
   "outputs": [],
   "source": [
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1740992778253,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "yMeGyHqd-qNp",
    "outputId": "076655c5-bcad-433e-ed11-639f2945a77e"
   },
   "outputs": [],
   "source": [
    "# Convert 'Month' to datetime and set as index\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1740891501558,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "FVVHmQANApIe",
    "outputId": "c50a632b-5ab7-481b-bd75-a27582a63a30"
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1740992784112,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "Zk1oBrwt_MJo",
    "outputId": "6603cf22-0112-4af1-d014-bbcc8e726c09"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1740992785874,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "h_gmiltf_QvK",
    "outputId": "06b1a5cc-5ce2-435b-c370-ce91792db0c5"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1740992793942,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "4ElEXi6i5weA",
    "outputId": "bb6886f0-932a-422c-a79e-f428801a0f73"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KIcsIpY_aTl"
   },
   "source": [
    "Observation:\n",
    "\n",
    "The data set has no missing values\n",
    "\n",
    "Data is recorded at a monthly frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOv3iRKkAv0n"
   },
   "source": [
    "### Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1740992796745,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "0HIFPFm45wUJ",
    "outputId": "3bb539a2-7624-4c1f-f93e-fd24dccbc7f4"
   },
   "outputs": [],
   "source": [
    "# Resample data to monthly frequency\n",
    "df = df.resample('M').sum()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 89,
     "status": "ok",
     "timestamp": 1740992805206,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "3-xZaec4IUFT",
    "outputId": "49225ecc-58d3-4ce1-ed0b-d3a329ff6205"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8I6m-jtBI4v"
   },
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ebaa7xl4B0AA"
   },
   "source": [
    "### Sales Trends Over time:\n",
    "This helps understanding the overall sales patterns to identify growth or decline periods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 1181,
     "status": "ok",
     "timestamp": 1740992817621,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "DjIIW39N5wRs",
    "outputId": "be6a6adf-4690-4525-da90-9ebad3b364af"
   },
   "outputs": [],
   "source": [
    "# Plot monthly sales\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['Monthly Sales'], label=\"Video Games Sales Data\")\n",
    "plt.title(\"Monthly Video Game Sales Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agxT4mt3C7FP"
   },
   "source": [
    "### Seasonal Patterns in Sales:\n",
    "\n",
    "This gives an understanding of the overall sales patterns by identifying growth or decline periods in seasons, to help with inventory management and marketing strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQFvSStgDjSM"
   },
   "source": [
    "Firstly Decompose the Time Series\n",
    "\n",
    "Decompose the time series into trend, seasonality, and residual components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740992824953,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "Vj95Q2w_Dn-D"
   },
   "outputs": [],
   "source": [
    "# Decompose the time series\n",
    "# Seasonal decomposition\n",
    "decomposition = seasonal_decompose(df['Monthly Sales'], model='additive', period=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "executionInfo": {
     "elapsed": 1665,
     "status": "ok",
     "timestamp": 1740992846001,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "epG0D1vpD28c",
    "outputId": "2a5ebab3-30ee-4034-c980-978ead9725af"
   },
   "outputs": [],
   "source": [
    "# Plot the decomposition component\n",
    "plt.figure(figsize=(12, 6))\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 537,
     "status": "ok",
     "timestamp": 1740992856124,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "lH_dd8YKD51T",
    "outputId": "3e5d9acf-9fda-47e3-bcee-7f268057b08d"
   },
   "outputs": [],
   "source": [
    "# Plot the seasonal component\n",
    "plt.figure(figsize=(12, 6))\n",
    "decomposition.seasonal.plot()\n",
    "plt.title(\"Seasonal Component of Sales\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6oJuQgbE6nk"
   },
   "source": [
    "### How Holidays and Promotions relate to the changes in Sales:\n",
    "\n",
    "This will help with Understanding the influence of holidays and promotions being crucial for marketing planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1740992864523,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "A0QTG5lVh-Wm",
    "outputId": "23619660-a850-45a9-f538-a8c9dbe7f552"
   },
   "outputs": [],
   "source": [
    "# Compare sales during holidays vs. non-holidays\n",
    "holiday_sales = df[df['Holiday'] == 1]['Monthly Sales']\n",
    "non_holiday_sales = df[df['Holiday'] == 0]['Monthly Sales']\n",
    "\n",
    "# Calculate average sales\n",
    "average_promotion_sales = round(holiday_sales.mean(), 2)\n",
    "average_non_promotion_sales = round(non_holiday_sales.mean(), 2)\n",
    "\n",
    "# Create DataFrame\n",
    "sales_comparison_df = pd.DataFrame({\n",
    "    'Condition': ['Holidays', 'Non-holidays'],\n",
    "    'Average Sales': [average_promotion_sales, average_non_promotion_sales]\n",
    "})\n",
    "\n",
    "sales_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1740992931304,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "zTkVyfdyQzNj",
    "outputId": "5251baf4-5686-47b9-be78-94d3e706cd8a"
   },
   "outputs": [],
   "source": [
    "# Display DataFrame\n",
    "print(sales_comparison_df)\n",
    "\n",
    "# Create pie chart\n",
    "labels = sales_comparison_df['Condition']\n",
    "sizes = sales_comparison_df['Average Sales']\n",
    "colors = ['#ff9999','#66b3ff']\n",
    "explode = (0.1, 0)  # explode the first slice (Holidays)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.title('Average Sales: Holidays vs. Non-holidays')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1740992991430,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "NbwF3ZXzFSla",
    "outputId": "01076e35-335a-4503-b67a-724308ef84a6"
   },
   "outputs": [],
   "source": [
    "# Compare sales during promotions vs. non-promotions\n",
    "promotion_sales = df[df['Promotion'] == 1]['Monthly Sales']\n",
    "non_promotion_sales = df[df['Promotion'] == 0]['Monthly Sales']\n",
    "\n",
    "# Calculate average sales\n",
    "average_promotion_sales = round(promotion_sales.mean(), 2)\n",
    "average_non_promotion_sales = round(non_promotion_sales.mean(), 2)\n",
    "\n",
    "# Create DataFrame\n",
    "promotion_sales_comparison_df = pd.DataFrame({\n",
    "    'Condition': ['Promotions', 'Non-Promotions'],\n",
    "    'Average Sales': [average_promotion_sales, average_non_promotion_sales]\n",
    "})\n",
    "\n",
    "promotion_sales_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1740993151327,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "lDTvIzhpRad4",
    "outputId": "e5dfce0c-d550-4013-baab-45f77e5af095"
   },
   "outputs": [],
   "source": [
    "# Create donut plot\n",
    "labels = promotion_sales_comparison_df['Condition']\n",
    "sizes = promotion_sales_comparison_df['Average Sales']\n",
    "colors = ['#ff9999','#66b3ff']\n",
    "explode = (0.1, 0)  # explode the first slice (Holidays)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90, wedgeprops=dict(width=0.3))\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.title('Average Sales: Promotions vs. Non-Promotions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vy-46uGWHQF1"
   },
   "source": [
    "### Influence of Sales by the the day of the week:\n",
    "\n",
    "Identifying the patterns in sales across days of the week to optimize promotional activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xEiLyh3gFSjf"
   },
   "outputs": [],
   "source": [
    "# Group sales by day of the week\n",
    "day_of_week_sales = df.groupby('DayOfWeek')['Monthly Sales'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1740891505381,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "TlHoozLZFSg6",
    "outputId": "e9502b0b-5d82-4476-b31d-153fce1680a9"
   },
   "outputs": [],
   "source": [
    "# Plot sales by day of the week\n",
    "plt.figure(figsize=(12, 6))\n",
    "day_of_week_sales.plot(kind='bar')\n",
    "plt.title(\"Average Sales by Day of the Week\")\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel(\"Average Sales\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQm3tCN0Iu9_"
   },
   "source": [
    "### Analysis of Sales Distribution\n",
    "Checking for the distribution of monthly sales to understand its spread and identify any outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1740891505381,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "liE-sX_bFSbq",
    "outputId": "e288e07f-abc7-41ce-a069-e533905ed31e"
   },
   "outputs": [],
   "source": [
    "# Plot distribution of monthly sales\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['Monthly Sales'], bins=20, kde=True)\n",
    "plt.title(\"Distribution of Monthly Sales\")\n",
    "plt.xlabel(\"Monthly Sales\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbwLOVveJPTv"
   },
   "source": [
    "###  Sales by Year\n",
    "Grouping sales by year to see the total and average sales for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1740891505381,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "utSevJCoFSYK",
    "outputId": "c2bedfd9-fc40-48d9-b457-f99278c2c9e7"
   },
   "outputs": [],
   "source": [
    "# Group by year and calculate total and average sales\n",
    "yearly_sales = df.groupby('Year')['Monthly Sales'].agg(['sum', 'mean'])\n",
    "\n",
    "# Plot yearly sales\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "yearly_sales['sum'].plot(kind='bar')\n",
    "plt.title(\"Total Sales by Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Total Sales\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "yearly_sales['mean'].plot(kind='bar')\n",
    "plt.title(\"Average Sales by Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Average Sales\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deimr9-CL7-F"
   },
   "source": [
    "### Sales by Day of the Week\n",
    "How sales vary across different days of the week.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1740891507185,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "-TsHnG0AFSNu",
    "outputId": "e5dea3b7-cf18-4863-ec2b-5dd84318f847"
   },
   "outputs": [],
   "source": [
    "# Group by day of the week and calculate total and average sales\n",
    "day_of_week_sales = df.groupby('DayOfWeek')['Monthly Sales'].agg(['sum', 'mean'])\n",
    "\n",
    "# Plot sales by day of the week\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "day_of_week_sales['sum'].plot(kind='bar')\n",
    "plt.title(\"Total Sales by Day of the Week\")\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel(\"Total Sales\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "day_of_week_sales['mean'].plot(kind='bar')\n",
    "plt.title(\"Average Sales by Day of the Week\")\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel(\"Average Sales\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CX9HNyhwMMuy"
   },
   "source": [
    "### Sales During Holidays and Promotions\n",
    "Analysis of how sales are influenced by holidays and promotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1740891507185,
     "user": {
      "displayName": "IBRAHIM ISMAILA",
      "userId": "14519943863888434268"
     },
     "user_tz": -60
    },
    "id": "RUKs2tkSFSK-",
    "outputId": "6cb41eb9-115d-4506-9482-30ce53f813e9"
   },
   "outputs": [],
   "source": [
    "# Group by holiday and calculate total and average sales\n",
    "holiday_sales = df.groupby('Holiday')['Monthly Sales'].agg(['sum', 'mean'])\n",
    "\n",
    "# Group by promotion and calculate total and average sales\n",
    "promotion_sales = df.groupby('Promotion')['Monthly Sales'].agg(['sum', 'mean'])\n",
    "\n",
    "# Plot sales during holidays and promotions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "holiday_sales['mean'].plot(kind='bar')\n",
    "plt.title(\"Average Sales During Holidays\")\n",
    "plt.xlabel(\"Holiday (1 = Yes, 0 = No)\")\n",
    "plt.ylabel(\"Average Sales\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "promotion_sales['mean'].plot(kind='bar')\n",
    "plt.title(\"Average Sales During Promotions\")\n",
    "plt.xlabel(\"Promotion (1 = Yes, 0 = No)\")\n",
    "plt.ylabel(\"Average Sales\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data for Correlation Analysis\n",
    "\n",
    "We’ll encode categorical features (e.g., Holiday, Promotion, Season), focus on numerical features for correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "df_encoded = df.copy()\n",
    "df_encoded['Holiday'] = df_encoded['Holiday'].astype(int)\n",
    "df_encoded['Promotion'] = df_encoded['Promotion'].astype(int)\n",
    "\n",
    "# Select all features (numerical + encoded categorical)\n",
    "all_features = df_encoded[['Monthly Sales', 'Year', 'DayOfWeek', 'Holiday', 'Promotion']]\n",
    "\n",
    "# Display the first few rows\n",
    "all_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Correlation Analysis\n",
    "Calculate Correlation Matrix\n",
    "\n",
    "We’ll calculate the Pearson correlation coefficient between all pairs of features.\n",
    "\n",
    "This measures the linear relationship between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = all_features.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the Correlation Matrix\n",
    "Visualize the correlation matrix using a heatmap for better interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of Correlations with Monthly Sales\n",
    "Focusing on the correlation between Monthly Sales and other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract correlations with Monthly Sales\n",
    "sales_correlation = correlation_matrix['Monthly Sales'].sort_values(ascending=False)\n",
    "\n",
    "# Display correlations\n",
    "print(sales_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insights\n",
    "\n",
    "`Strong Positive Correlation`: Features with a correlation coefficient close to +1 indicate a strong positive relationship with Monthly Sales.\n",
    "\n",
    "`Strong Negative Correlation`: Features with a correlation coefficient close to -1 indicate a strong negative relationship with Monthly Sales.\n",
    "\n",
    "`Weak or No Correlation`: Features with a correlation coefficient close to 0 indicate little to no relationship with Monthly Sales.\n",
    "\n",
    "Note:\n",
    "\n",
    "If Promotion has a high positive correlation with Monthly Sales, it means promotions are associated with higher sales.\n",
    "\n",
    "If DayOfWeek has a low correlation with Monthly Sales, it means the day of the week has little impact on sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of Findings\n",
    "Trends: Overall sales trends over time (increasing, decreasing, or stable).\n",
    "\n",
    "Seasonality: Strong seasonal patterns in sales (e.g., higher sales in certain months or seasons).\n",
    "\n",
    "Holidays and Promotions: Impact of holidays and promotions on sales.\n",
    "\n",
    "Day of the Week: Variations in sales across days of the week.\n",
    "\n",
    "New Features: Insights from the \"Year-Month\" and \"Season\" features.\n",
    "\n",
    "\n",
    "\n",
    "#### Next Steps\n",
    "Feature Engineering: Insights from the correlation analysis will be applied to select and or transform new features (e.g., \"Season\") in the time series models.\n",
    "\n",
    " hence:\n",
    "\n",
    "  - Include Features: Features with strong correlations (positive or negative) with Monthly Sales.\n",
    "\n",
    "  - Exclude Features: Features with weak or no correlation with Monthly Sales (unless they have domain importance)\n",
    "\n",
    "Model Selection: Based on the EDA, appropriate time series models will be selected (e.g., ARIMA, Holt-Winters).\n",
    "\n",
    "Model Implementation: Based on findings, Select and implement models. Selected Models will be Implemented and tuned.\n",
    "  - Fine-Tune Models: Experiment with hyperparameters (e.g., ARIMA orders, seasonal periods).\n",
    "\n",
    "Validate Models: Models will be Evaluated on a test set.\n",
    "\n",
    "Forecasting: The best model will be used to make future sales forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features\n",
    "\n",
    "Since the dataset includes categorical variables (Category, Platform, Holiday, Promotion), we need to encode them before feeding them into the models.\n",
    "\n",
    "### Encoding Techniques\n",
    "\n",
    "- **One-Hot Encoding (OHE)**: Suitable for nominal categorical variables (e.g., Category, Platform).\n",
    "- **Label Encoding**: Used for binary variables (Holiday, Promotion).\n",
    "\n",
    "### Implementation of Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to category dtype\n",
    "df[\"Category\"] = df[\"Category\"].astype(\"category\")\n",
    "df[\"Platform\"] = df[\"Platform\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoding\n",
    "df = pd.get_dummies(df, columns=[\"Category\", \"Platform\"], drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode binary categorical variables\n",
    "df[\"Holiday\"] = df[\"Holiday\"].astype(int)\n",
    "df[\"Promotion\"] = df[\"Promotion\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature Engineering\n",
    "\n",
    "Create Lag Features & Rolling Statistics\n",
    "\n",
    "To help models capture historical trends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Lag_1\"] = df[\"Monthly Sales\"].shift(1)\n",
    "df[\"Lag_2\"] = df[\"Monthly Sales\"].shift(2)\n",
    "df[\"Rolling_Mean_3\"] = df[\"Monthly Sales\"].rolling(window=3).mean()\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Performance Evaluation\n",
    "\n",
    "### Train-Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df) * 0.8)\n",
    "train, test = df.iloc[:train_size], df.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA\n",
    "\n",
    "To fit the ARIMA model and make predictions, there is need to determine the values of p, d \n",
    "and q parameters. \n",
    "\n",
    "Check the Autocorrelation (ACF) and the Partial Auto-Correlation Function (PACF), plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ACF to find q (MA component)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_acf(df[\"Monthly Sales\"], lags=30)\n",
    "plt.title(\"Auto-Correlation Function (ACF) - Identifying q\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PACF to find p (AR component)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_pacf(df[\"Monthly Sales\"], lags=30)\n",
    "plt.title(\"Partial Auto-Correlation Function (PACF) - Identifying p\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting ACF & PACF Plots for Determining p and q\n",
    "\n",
    "#### From the PACF plot (Identifying p):\n",
    "        - The first lag (lag 1) has a strong positive spike.\n",
    "        - The values cut off sharply after lag 1 (remaining lags are within the confidence interval).\n",
    "        - This suggests p = 1 for the AR (Auto-Regressive) component.\n",
    "        - From the ACF plot (Identifying q):\n",
    "\n",
    "#### The ACF also cuts off after lag 1, meaning that the q value is also 1 for the MA (Moving Average) component.\n",
    "        - Final ARIMA Order Based on Plots\n",
    "        - p = 1 (from PACF cutoff)\n",
    "        - d = 0 (since data is already stationary)\n",
    "        - q = 1 (from ACF cutoff)\n",
    "\n",
    "Therefore, the best model to start with is ARIMA(1,0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the ARIMA model\n",
    "arima_model = ARIMA(train[\"Monthly Sales\"], order=(1, 0, 1)).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast the next 4 months\n",
    "arima_forecast = arima_model.forecast(steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast next 4 months\n",
    "forecast_steps = 4\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.DateOffset(months=1), periods=forecast_steps, freq='MS')\n",
    "arima_forecast = arima_model.forecast(steps=forecast_steps)\n",
    "\n",
    "# Convert forecast to DataFrame\n",
    "arima_forecast = pd.DataFrame({\"Month\": future_dates, \"ARIMA(1,0,1) Forecasted Sales\": arima_forecast.values})\n",
    "arima_forecast.set_index(\"Month\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train['Monthly Sales'], label=\"Training Data\")\n",
    "plt.plot(test['Monthly Sales'], label=\"Test Data\")\n",
    "plt.plot(arima_forecast, label=\"ARIMA Forecast\")\n",
    "plt.title(\"ARIMA Forecasting\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Monthly Sales\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n4-Month ARIMA Forecast:\")\n",
    "print(arima_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exponential Smoothing (ETS Model), Holt-Winters (Additive and Multiplicative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the ETS(A,A,A) model\n",
    "ets_model = ExponentialSmoothing(df[\"Monthly Sales\"], trend=\"add\", seasonal=\"add\", seasonal_periods=12).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast the next 4 months\n",
    "forecast_steps = 4\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.DateOffset(months=1), periods=forecast_steps, freq='MS')\n",
    "ets_forecast = ets_model.forecast(steps=forecast_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to hold both actual and forecasted values\n",
    "forecast_df = pd.DataFrame({\n",
    "    \"Date\": future_dates,\n",
    "    \"Forecasted Sales\": ets_forecast\n",
    "}).set_index(\"Date\")\n",
    "\n",
    "# Concatenate actual and forecasted data\n",
    "combined_df = pd.concat([df[\"Monthly Sales\"], forecast_df[\"Forecasted Sales\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. forecasted sales\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df.index, df[\"Monthly Sales\"], label=\"Actual Sales\", color ='blue')\n",
    "plt.plot(forecast_df.index, forecast_df[\"Forecasted Sales\"], label=\"Forecasted Sales\", linestyle='--', color='red')\n",
    "plt.title(\"Actual vs. Forecasted Sales\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.legend()\n",
    "#plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display forecast\n",
    "print(\"\\n4-Month ETS Forecast:\")\n",
    "print(ets_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Exponential Smoothing (SES)\n",
    "\n",
    "SES is a simple model that uses a weighted average of past observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the SES model (Simple Exponential Smoothing)\n",
    "ses_model = SimpleExpSmoothing(df[\"Monthly Sales\"]).fit(smoothing_level=0.2, optimized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast the next 4 months\n",
    "forecast_steps = 4\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.DateOffset(months=1), periods=forecast_steps, freq='MS')\n",
    "ses_forecast = ses_model.forecast(steps=forecast_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to hold both actual and forecasted values\n",
    "forecast_df = pd.DataFrame({\n",
    "    \"Date\": future_dates,\n",
    "    \"Forecasted Sales\": ses_forecast\n",
    "}).set_index(\"Date\")\n",
    "\n",
    "# Concatenate actual and forecasted data for plotting\n",
    "combined_df = pd.concat([df[\"Monthly Sales\"], forecast_df[\"Forecasted Sales\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. forecasted sales\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df.index, df[\"Monthly Sales\"], label=\"Actual Sales\", color='blue')\n",
    "plt.plot(forecast_df.index, forecast_df[\"Forecasted Sales\"], label=\"Forecasted Sales (SES)\", linestyle='--', color='red')\n",
    "plt.title(\"Actual vs. Forecasted Sales (SES Model)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.legend()\n",
    "#plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train['Monthly Sales'], label=\"Training Data\")\n",
    "plt.plot(test['Monthly Sales'], label=\"Test Data\")\n",
    "plt.plot(ses_forecast, label=\"SES Forecast\")\n",
    "plt.title(\"Single Exponential Smoothing (SES)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Monthly Sales\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMA Model and Plot Actual vs. Forecasted Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the SARIMA model\n",
    "sarima_model = SARIMAX(df[\"Monthly Sales\"], \n",
    "                       order=(1, 1, 1),  # Non-seasonal ARIMA(p, d, q)\n",
    "                       seasonal_order=(1, 1, 1, 12)  # Seasonal ARIMA(P, D, Q, s)\n",
    "                      ).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast the next 4 months\n",
    "forecast_steps = 4\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.DateOffset(months=1), periods=forecast_steps, freq='MS')\n",
    "sarima_forecast = sarima_model.get_forecast(steps=forecast_steps).predicted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to hold both actual and forecasted values\n",
    "forecast_df = pd.DataFrame({\n",
    "    \"Date\": future_dates,\n",
    "    \"Forecasted Sales\": sarima_forecast.values\n",
    "}).set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate actual and forecasted data for plotting\n",
    "combined_df = pd.concat([df[\"Monthly Sales\"], forecast_df[\"Forecasted Sales\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. forecasted sales\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df.index, df[\"Monthly Sales\"], label=\"Actual Sales\", color='blue')\n",
    "plt.plot(forecast_df.index, forecast_df[\"Forecasted Sales\"], label=\"Forecasted Sales (SARIMA)\", linestyle='--', color='red')\n",
    "plt.title(\"Actual vs. Forecasted Sales (SARIMA Model)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.legend()\n",
    "#plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Forecast next 4 months using both all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "forecast_steps = 4\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.DateOffset(months=1), periods=forecast_steps, freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ETS (Exponential Smoothing) Model\n",
    "ets_model = ExponentialSmoothing(df[\"Monthly Sales\"], trend=\"add\", seasonal=\"add\", seasonal_periods=12).fit()\n",
    "ets_forecast = ets_model.forecast(steps=forecast_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA Model\n",
    "arima_model = ARIMA(df[\"Monthly Sales\"], order=(1, 1, 1)).fit()\n",
    "arima_forecast = arima_model.forecast(steps=forecast_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SES (Simple Exponential Smoothing) Model\n",
    "ses_model = SimpleExpSmoothing(df[\"Monthly Sales\"]).fit(smoothing_level=0.2, optimized=True)\n",
    "ses_forecast = ses_model.forecast(steps=forecast_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SARIMA Model\n",
    "sarima_model = SARIMAX(df[\"Monthly Sales\"], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12)).fit()\n",
    "sarima_forecast = sarima_model.get_forecast(steps=forecast_steps).predicted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert forecasts to DataFrames\n",
    "ets_forecast_df = pd.DataFrame({\"Month\": future_dates, \"ETS Forecasted Sales\": ets_forecast.values}).set_index(\"Month\")\n",
    "arima_forecast_df = pd.DataFrame({\"Month\": future_dates, \"ARIMA Forecasted Sales\": arima_forecast.values}).set_index(\"Month\")\n",
    "ses_forecast_df = pd.DataFrame({\"Month\": future_dates, \"SES Forecasted Sales\": ses_forecast.values}).set_index(\"Month\")\n",
    "sarima_forecast_df = pd.DataFrame({\"Month\": future_dates, \"SARIMA Forecasted Sales\": sarima_forecast.values}).set_index(\"Month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge forecasts for comparison\n",
    "forecast_comparison_df = ets_forecast_df.merge(arima_forecast_df, left_index=True, right_index=True)\n",
    "forecast_comparison_df = forecast_comparison_df.merge(ses_forecast_df, left_index=True, right_index=True)\n",
    "forecast_comparison_df = forecast_comparison_df.merge(sarima_forecast_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. forecasted sales\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot actual sales\n",
    "plt.plot(df.index, df[\"Monthly Sales\"], label=\"Actual Sales\", color=\"blue\")\n",
    "\n",
    "# Plot forecasts from each model\n",
    "plt.plot(ets_forecast_df.index, ets_forecast_df[\"ETS Forecasted Sales\"], label=\"ETS Forecast\", color=\"green\", linestyle=\"dashed\")\n",
    "plt.plot(arima_forecast_df.index, arima_forecast_df[\"ARIMA Forecasted Sales\"], label=\"ARIMA Forecast\", color=\"red\", linestyle=\"dashed\")\n",
    "plt.plot(ses_forecast_df.index, ses_forecast_df[\"SES Forecasted Sales\"], label=\"SES Forecast\", color=\"yellow\", linestyle=\"dashed\")\n",
    "plt.plot(sarima_forecast_df.index, sarima_forecast_df[\"SARIMA Forecasted Sales\"], label=\"SARIMA Forecast\", color=\"purple\", linestyle=\"dashed\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Sales Volume\")\n",
    "plt.title(\"Sales Forecast Comparison: ETS, ARIMA, SES, SARIMA\")\n",
    "plt.legend()\n",
    "#plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display forecast comparison\n",
    "print(\"\\nForecast Comparison (Next 4 Months):\")\n",
    "print(forecast_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_comparison_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute in-sample errors for ETS model\n",
    "ets_in_sample_pred = ets_model.fittedvalues\n",
    "ets_mse = mean_squared_error(df[\"Monthly Sales\"], ets_in_sample_pred)\n",
    "ets_rmse = np.sqrt(ets_mse)  # Root Mean Squared Error\n",
    "ets_mae = mean_absolute_error(df[\"Monthly Sales\"], ets_in_sample_pred)\n",
    "ets_mape = mean_absolute_percentage_error(df[\"Monthly Sales\"], ets_in_sample_pred)\n",
    "ets_r2 = r2_score(df[\"Monthly Sales\"], ets_in_sample_pred)\n",
    "\n",
    "# Compute in-sample errors for ARIMA model\n",
    "arima_in_sample_pred = arima_model.fittedvalues\n",
    "arima_mse = mean_squared_error(df[\"Monthly Sales\"], arima_in_sample_pred)\n",
    "arima_rmse = np.sqrt(arima_mse)\n",
    "arima_mae = mean_absolute_error(df[\"Monthly Sales\"], arima_in_sample_pred)\n",
    "arima_mape = mean_absolute_percentage_error(df[\"Monthly Sales\"], arima_in_sample_pred)\n",
    "arima_r2 = r2_score(df[\"Monthly Sales\"], arima_in_sample_pred)\n",
    "\n",
    "# Compute in-sample errors for SES model\n",
    "ses_in_sample_pred = ses_model.fittedvalues\n",
    "ses_mse = mean_squared_error(df[\"Monthly Sales\"], ses_in_sample_pred)\n",
    "ses_rmse = np.sqrt(ses_mse)\n",
    "ses_mae = mean_absolute_error(df[\"Monthly Sales\"], ses_in_sample_pred)\n",
    "ses_mape = mean_absolute_percentage_error(df[\"Monthly Sales\"], ses_in_sample_pred)\n",
    "ses_r2 = r2_score(df[\"Monthly Sales\"], ses_in_sample_pred)\n",
    "\n",
    "# Compute in-sample errors for SARIMA model\n",
    "sarima_in_sample_pred = sarima_model.fittedvalues\n",
    "sarima_mse = mean_squared_error(df[\"Monthly Sales\"], sarima_in_sample_pred)\n",
    "sarima_rmse = np.sqrt(sarima_mse)\n",
    "sarima_mae = mean_absolute_error(df[\"Monthly Sales\"], sarima_in_sample_pred)\n",
    "sarima_mape = mean_absolute_percentage_error(df[\"Monthly Sales\"], sarima_in_sample_pred)\n",
    "sarima_r2 = r2_score(df[\"Monthly Sales\"], sarima_in_sample_pred)\n",
    "\n",
    "# Create DataFrame to compare in-sample errors\n",
    "in_sample_errors = pd.DataFrame({\n",
    "    \"Model\": [\"ETS\", \"ARIMA\", \"SES\", \"SARIMA\"],\n",
    "    \"MSE\": [ets_mse, arima_mse, ses_mse, sarima_mse],\n",
    "    \"RMSE\": [ets_rmse, arima_rmse, ses_rmse, sarima_rmse],\n",
    "    \"MAE\": [ets_mae, arima_mae, ses_mae, sarima_mae],\n",
    "    \"MAPE\": [ets_mape, arima_mape, ses_mape, sarima_mape],\n",
    "    \"R2 Score\": [ets_r2, arima_r2, ses_r2, sarima_r2]\n",
    "})\n",
    "\n",
    "# Display in-sample error comparison\n",
    "print(\"\\nIn-Sample Error Comparison:\")\n",
    "print(in_sample_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sample_errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute holdout sample errors (next 4 months forecasts)\n",
    "ets_holdout_mse = mean_squared_error(df[\"Monthly Sales\"].iloc[-forecast_steps:], ets_forecast.values)\n",
    "ets_holdout_rmse = np.sqrt(ets_holdout_mse)\n",
    "ets_holdout_mae = mean_absolute_error(df[\"Monthly Sales\"].iloc[-forecast_steps:], ets_forecast.values)\n",
    "ets_holdout_mape = mean_absolute_percentage_error(df[\"Monthly Sales\"].iloc[-forecast_steps:], ets_forecast.values)\n",
    "ets_holdout_r2 = r2_score(df[\"Monthly Sales\"].iloc[-forecast_steps:], ets_forecast.values)\n",
    "\n",
    "arima_holdout_mse = mean_squared_error(df[\"Monthly Sales\"].iloc[-forecast_steps:], arima_forecast.values)\n",
    "arima_holdout_rmse = np.sqrt(arima_holdout_mse)\n",
    "arima_holdout_mae = mean_absolute_error(df[\"Monthly Sales\"].iloc[-forecast_steps:], arima_forecast.values)\n",
    "arima_holdout_mape = mean_absolute_percentage_error(df[\"Monthly Sales\"].iloc[-forecast_steps:], arima_forecast.values)\n",
    "arima_holdout_r2 = r2_score(df[\"Monthly Sales\"].iloc[-forecast_steps:], arima_forecast.values)\n",
    "\n",
    "ses_holdout_mse = mean_squared_error(df[\"Monthly Sales\"].iloc[-forecast_steps:], ses_forecast.values)\n",
    "ses_holdout_rmse = np.sqrt(ses_holdout_mse)\n",
    "ses_holdout_mae = mean_absolute_error(df[\"Monthly Sales\"].iloc[-forecast_steps:], ses_forecast.values)\n",
    "ses_holdout_mape = mean_absolute_percentage_error(df[\"Monthly Sales\"].iloc[-forecast_steps:], ses_forecast.values)\n",
    "ses_holdout_r2 = r2_score(df[\"Monthly Sales\"].iloc[-forecast_steps:], ses_forecast.values)\n",
    "\n",
    "sarima_holdout_mse = mean_squared_error(df[\"Monthly Sales\"].iloc[-forecast_steps:], sarima_forecast.values)\n",
    "sarima_holdout_rmse = np.sqrt(sarima_holdout_mse)\n",
    "sarima_holdout_mae = mean_absolute_error(df[\"Monthly Sales\"].iloc[-forecast_steps:], sarima_forecast.values)\n",
    "sarima_holdout_mape = mean_absolute_percentage_error(df[\"Monthly Sales\"].iloc[-forecast_steps:], sarima_forecast.values)\n",
    "sarima_holdout_r2 = r2_score(df[\"Monthly Sales\"].iloc[-forecast_steps:], ses_forecast.values)\n",
    "\n",
    "# Create DataFrame to compare holdout errors\n",
    "holdout_errors = pd.DataFrame({\n",
    "    \"Model\": [\"ETS\", \"ARIMA\", \"SES\", \"SARIMA\"],\n",
    "    \"MSE\": [ets_holdout_mse, arima_holdout_mse, ses_holdout_mse, sarima_holdout_mse],\n",
    "    \"RMSE\": [ets_holdout_rmse, arima_holdout_rmse, ses_holdout_rmse, sarima_holdout_rmse],\n",
    "    \"MAE\": [ets_holdout_mae, arima_holdout_mae, ses_holdout_mae, sarima_holdout_mae],\n",
    "    \"MAPE\": [ets_holdout_mape, arima_holdout_mape, ses_holdout_mape, sarima_holdout_mape],\n",
    "    \"R2 Score\": [ets_holdout_r2, arima_holdout_r2, ses_holdout_r2, sarima_holdout_r2]\n",
    "})\n",
    "\n",
    "# Display holdout sample error comparison\n",
    "print(\"\\nHoldout Error Comparison (Next 4 Months):\")\n",
    "print(holdout_errors)\n",
    "\n",
    "# Determine the best model based on in-sample MAPE\n",
    "best_model = in_sample_errors.loc[in_sample_errors[\"MAPE\"].idxmin(), \"Model\"]\n",
    "print(f\"\\nThe best model based on in-sample MAPE is: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save ARIMA model\n",
    "with open(\"arima_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(arima_model, f)\n",
    "print(\"ARIMA model saved as arima_model.pkl\")\n",
    "\n",
    "# Save Holt-Winters (ETS) model\n",
    "with open(\"hw_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ets_model, f)\n",
    "print(\"Holt-Winters model saved as hw_model.pkl\")\n",
    "\n",
    "# Save SES model\n",
    "with open(\"ses_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ses_model, f)\n",
    "print(\"SES model saved as ses_model.pkl\")\n",
    "\n",
    "# Save SARIMA model\n",
    "with open(\"sarima_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sarima_model, f)\n",
    "print(\"SARIMA model saved as sarima_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log MlFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track using mlflow\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MLflow Tracking URI\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# Set MLflow Experiment Tracking \n",
    "mlflow.set_experiment(\"time_series_forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define forecast steps\n",
    "forecast_steps = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ ETS Model ------------------\n",
    "# Train ETS model\n",
    "ets_model = ExponentialSmoothing(df[\"Monthly Sales\"], trend=\"add\", seasonal=\"add\", seasonal_periods=12).fit()\n",
    "\n",
    "# Extract ETS parameters\n",
    "alpha = ets_model.params['smoothing_level']\n",
    "beta = ets_model.params['smoothing_trend']\n",
    "gamma = ets_model.params['smoothing_seasonal']\n",
    "\n",
    "# Get in-sample predictions and metrics\n",
    "ets_pred = ets_model.fittedvalues\n",
    "ets_mse = mean_squared_error(df[\"Monthly Sales\"], ets_pred)\n",
    "ets_mae = mean_absolute_error(df[\"Monthly Sales\"], ets_pred)\n",
    "ets_mape = mean_absolute_percentage_error(df[\"Monthly Sales\"], ets_pred)\n",
    "\n",
    "# Log ETS model in MLflow\n",
    "with mlflow.start_run(run_name=\"ETS_Model\"):\n",
    "    mlflow.log_param(\"Model\", \"ETS\")\n",
    "    mlflow.log_param(\"Alpha\", alpha)\n",
    "    mlflow.log_param(\"Beta\", beta)\n",
    "    mlflow.log_param(\"Gamma\", gamma)\n",
    "\n",
    "    mlflow.log_metric(\"MSE\", ets_mse)\n",
    "    mlflow.log_metric(\"MAE\", ets_mae)\n",
    "    mlflow.log_metric(\"MAPE\", ets_mape)\n",
    "\n",
    "    mlflow.sklearn.log_model(ets_model, \"ETS_Model\")\n",
    "\n",
    "print(\"ETS Model logged in MLflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ ARIMA Model ------------------\n",
    "# Define ARIMA parameters (example: p=1, d=1, q=1)\n",
    "p, d, q = 1, 1, 1\n",
    "arima_model = ARIMA(df[\"Monthly Sales\"], order=(p, d, q)).fit()\n",
    "\n",
    "# Get in-sample predictions and metrics\n",
    "arima_pred = arima_model.fittedvalues\n",
    "arima_mse = mean_squared_error(df[\"Monthly Sales\"], arima_pred)\n",
    "arima_mae = mean_absolute_error(df[\"Monthly Sales\"], arima_pred)\n",
    "arima_mape = mean_absolute_percentage_error(df[\"Monthly Sales\"], arima_pred)\n",
    "\n",
    "# Log ARIMA model in MLflow\n",
    "with mlflow.start_run(run_name=\"ARIMA_Model\"):\n",
    "    mlflow.log_param(\"p\", p)\n",
    "    mlflow.log_param(\"d\", d)\n",
    "    mlflow.log_param(\"q\", q)\n",
    "\n",
    "    mlflow.log_metric(\"MSE\", arima_mse)\n",
    "    mlflow.log_metric(\"MAE\", arima_mae)\n",
    "    mlflow.log_metric(\"MAPE\", arima_mape)\n",
    "\n",
    "    mlflow.sklearn.log_model(arima_model, \"ARIMA_Model\")\n",
    "\n",
    "print(\"ARIMA Model logged in MLflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ SES Model ------------------\n",
    "# Train SES model\n",
    "ses_model = SimpleExpSmoothing(df[\"Monthly Sales\"]).fit(smoothing_level=0.2, optimized=True)\n",
    "\n",
    "# Get in-sample predictions and metrics\n",
    "ses_pred = ses_model.fittedvalues\n",
    "ses_mse = mean_squared_error(df[\"Monthly Sales\"], ses_pred)\n",
    "ses_mae = mean_absolute_error(df[\"Monthly Sales\"], ses_pred)\n",
    "ses_mape = mean_absolute_percentage_error(df[\"Monthly Sales\"], ses_pred)\n",
    "\n",
    "# Log SES model in MLflow\n",
    "with mlflow.start_run(run_name=\"SES_Model\"):\n",
    "    mlflow.log_param(\"Model\", \"SES\")\n",
    "    mlflow.log_param(\"Smoothing Level\", ses_model.params[\"smoothing_level\"])\n",
    "\n",
    "    mlflow.log_metric(\"MSE\", ses_mse)\n",
    "    mlflow.log_metric(\"MAE\", ses_mae)\n",
    "    mlflow.log_metric(\"MAPE\", ses_mape)\n",
    "\n",
    "    mlflow.sklearn.log_model(ses_model, \"SES_Model\")\n",
    "\n",
    "print(\"SES Model logged in MLflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ SARIMA Model ------------------\n",
    "# Train SARIMA model\n",
    "sarima_model = SARIMAX(df[\"Monthly Sales\"], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12)).fit()\n",
    "\n",
    "# Get in-sample predictions and metrics\n",
    "sarima_pred = sarima_model.fittedvalues\n",
    "sarima_mse = mean_squared_error(df[\"Monthly Sales\"], sarima_pred)\n",
    "sarima_mae = mean_absolute_error(df[\"Monthly Sales\"], sarima_pred)\n",
    "sarima_mape = mean_absolute_percentage_error(df[\"Monthly Sales\"], sarima_pred)\n",
    "\n",
    "# Log SARIMA model in MLflow\n",
    "with mlflow.start_run(run_name=\"SARIMA_Model\"):\n",
    "    mlflow.log_param(\"Model\", \"SARIMA\")\n",
    "    mlflow.log_param(\"Seasonal Order\", \"(1, 1, 1, 12)\")\n",
    "\n",
    "    mlflow.log_metric(\"MSE\", sarima_mse)\n",
    "    mlflow.log_metric(\"MAE\", sarima_mae)\n",
    "    mlflow.log_metric(\"MAPE\", sarima_mape)\n",
    "\n",
    "    mlflow.sklearn.log_model(sarima_model, \"SARIMA_Model\")\n",
    "\n",
    "print(\"SARIMA Model logged in MLflow.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Month Forecasts Using MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define forecast parameters\n",
    "forecast_steps = 4\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.DateOffset(months=1), periods=forecast_steps, freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MLflow Experiment\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"time_series_forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ ETS Model ------------------\n",
    "# Forecast with ETS Model\n",
    "ets_forecast = ets_model.forecast(steps=forecast_steps)\n",
    "ets_forecast_df = pd.DataFrame({\"Month\": future_dates, \"ETS Forecast\": ets_forecast.values})\n",
    "ets_forecast_df.set_index(\"Month\", inplace=True)\n",
    "\n",
    "# Log ETS Forecast Results in MLflow\n",
    "ets_forecast_df.to_csv(\"ets_forecast.csv\", index=True)\n",
    "with mlflow.start_run(run_name=\"ETS_Forecast\"):\n",
    "    mlflow.log_param(\"Model\", \"ETS\")\n",
    "    mlflow.log_artifact(\"ets_forecast.csv\")\n",
    "\n",
    "print(\"ETS Forecast logged in MLflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ ARIMA Model ------------------\n",
    "# Forecast with ARIMA Model\n",
    "arima_forecast = arima_model.forecast(steps=forecast_steps)\n",
    "arima_forecast_df = pd.DataFrame({\"Month\": future_dates, \"ARIMA Forecast\": arima_forecast.values})\n",
    "arima_forecast_df.set_index(\"Month\", inplace=True)\n",
    "\n",
    "# Log ARIMA Forecast Results in MLflow\n",
    "arima_forecast_df.to_csv(\"arima_forecast.csv\", index=True)\n",
    "with mlflow.start_run(run_name=\"ARIMA_Forecast\"):\n",
    "    mlflow.log_param(\"Model\", \"ARIMA\")\n",
    "    mlflow.log_artifact(\"arima_forecast.csv\")\n",
    "\n",
    "print(\"ARIMA Forecast logged in MLflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ SES Model ------------------\n",
    "# Forecast with SES Model\n",
    "ses_forecast = ses_model.forecast(steps=forecast_steps)\n",
    "ses_forecast_df = pd.DataFrame({\"Month\": future_dates, \"SES Forecast\": ses_forecast.values})\n",
    "ses_forecast_df.set_index(\"Month\", inplace=True)\n",
    "\n",
    "# Log SES Forecast Results in MLflow\n",
    "ses_forecast_df.to_csv(\"ses_forecast.csv\", index=True)\n",
    "with mlflow.start_run(run_name=\"SES_Forecast\"):\n",
    "    mlflow.log_param(\"Model\", \"SES\")\n",
    "    mlflow.log_artifact(\"ses_forecast.csv\")\n",
    "\n",
    "print(\"SES Forecast logged in MLflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ SARIMA Model ------------------\n",
    "# Forecast with SARIMA Model\n",
    "sarima_forecast = sarima_model.get_forecast(steps=forecast_steps).predicted_mean\n",
    "sarima_forecast_df = pd.DataFrame({\"Month\": future_dates, \"SARIMA Forecast\": sarima_forecast.values})\n",
    "sarima_forecast_df.set_index(\"Month\", inplace=True)\n",
    "\n",
    "# Log SARIMA Forecast Results in MLflow\n",
    "sarima_forecast_df.to_csv(\"sarima_forecast.csv\", index=True)\n",
    "with mlflow.start_run(run_name=\"SARIMA_Forecast\"):\n",
    "    mlflow.log_param(\"Model\", \"SARIMA\")\n",
    "    mlflow.log_artifact(\"sarima_forecast.csv\")\n",
    "\n",
    "print(\"SARIMA Forecast logged in MLflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Combine and Save Forecasts ------------------\n",
    "# Combine all forecasts for comparison\n",
    "combined_forecasts_df = pd.concat([ets_forecast_df, arima_forecast_df, ses_forecast_df, sarima_forecast_df], axis=1)\n",
    "combined_forecasts_df.to_csv(\"combined_forecasts.csv\", index=True)\n",
    "\n",
    "# Log combined forecasts in MLflow\n",
    "with mlflow.start_run(run_name=\"Combined_Forecast\"):\n",
    "    mlflow.log_artifact(\"combined_forecasts.csv\")\n",
    "\n",
    "print(\"All forecasted results logged in MLflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 folds\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for train_index, test_index in tscv.split(df):\n",
    "    train, test = df[train_index], df[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPNE7oS80LfdegrJXt2cVYT",
   "mount_file_id": "1LEuIzicIkSYjCuvv29HDNNsqheahYrDr",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
